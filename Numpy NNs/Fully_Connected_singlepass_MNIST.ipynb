{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiOa+POWjTis34uyJV9pyo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stewartjollymore/MNIST_NNs/blob/main/Fully_Connected_singlepass_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1MuwJwbZ4T0"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "#Below we separate and arange the data as seen around the web\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 1, 28*28)\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "# encode output which is a number in range [0,9] into a vector of size 10\n",
        "# e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "# same for test data : 10000 samples\n",
        "x_test = x_test.reshape(x_test.shape[0], 1, 28*28)\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the layer dimensions\n",
        "\n",
        "input_size1 = 28*28\n",
        "output_size1 = 100\n",
        "input_size2 = 100\n",
        "output_size2 = 50\n",
        "input_sizefinal = 50\n",
        "output_sizefinal = 10"
      ],
      "metadata": {
        "id": "00xRUzVwaUjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#Initialze weights and biases\n",
        "\n",
        "w1 = np.random.rand(input_size1, output_size1) - 0.5\n",
        "b1 = np.random.rand(1, output_size1) - 0.5\n",
        "\n",
        "w2 = np.random.rand(input_size2, output_size2) - 0.5\n",
        "b2 = np.random.rand(1, output_size2) - 0.5\n",
        "\n",
        "w3 = np.random.rand(input_sizefinal, output_sizefinal) -0.5\n",
        "b3 = np.random.rand(1, output_sizefinal) - 0.5"
      ],
      "metadata": {
        "id": "u8KCrq5deGU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras as ks\n",
        "\n",
        "#Define activations for forward prop and backprop\n",
        "\n",
        "def sigmd(x):\n",
        "  return  1/(1+np.exp(-x))\n",
        "\n",
        "def gradient(x):\n",
        "  return sigmd(x)*(1-sigmd(x))\n"
      ],
      "metadata": {
        "id": "qh_nNjvlhD1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Single pass for a single data element\n",
        "\n",
        "single_xtrain = x_train[0]\n",
        "single_ytrain = y_train[0]\n",
        "\n",
        "#Pass through first hidden layer and activation neruon\n",
        "layer1 = np.dot(single_xtrain,w1)+b1\n",
        "act_layer1 = sigmd(layer1)\n",
        "\n",
        "#Pass through second hidden layer and activation neuron\n",
        "layer2 = np.dot(act_layer1,w2)+b2\n",
        "act_layer2 = sigmd(layer2)\n",
        "\n",
        "#Pass through output layer and acrivation neuron\n",
        "layer3 = np.dot(act_layer2,w3)+b3\n",
        "output = sigmd(layer3)"
      ],
      "metadata": {
        "id": "tUtvhPZrSkqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the error metrics\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true-y_pred, 2));\n",
        "\n",
        "def mse_grad(y_true, y_pred):\n",
        "    return 2*(y_pred-y_true)/y_true.size;"
      ],
      "metadata": {
        "id": "MvBV7mzjrBqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mesuring measn squared error\n",
        "output_error = mse(single_ytrain, output)\n",
        "output_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlhw0pWFvJn_",
        "outputId": "bc60652a-e654-47a6-d54c-a882321a84e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36345142888109305"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Backward Propigation steps\n",
        "\n",
        "#Define batch size and learning rate\n",
        "N = single_ytrain.size\n",
        "learning_rate = 0.1\n",
        "\n",
        "#calculate the output error\n",
        "output_error = output - single_ytrain\n",
        "\n",
        "#Backprop through output layer\n",
        "output_grad = output_error * gradient(output)\n",
        "layer3_error = np.dot(output_grad, w3.T)\n",
        "\n",
        "#Backkprop through second hidden layer\n",
        "layer3_grad = layer3_error * gradient(act_layer2)\n",
        "layer2_error = np.dot(layer3_grad, w2.T)\n",
        "\n",
        "#Backprop through first hidden layer\n",
        "layer2_grad = layer2_error * gradient(act_layer1)\n",
        "layer1_error = np.dot(layer2_grad, w1.T)\n",
        "\n",
        "#Calculating the graident back to the input\n",
        "layer1_grad = layer1_error * gradient(single_xtrain)\n",
        "\n",
        "#Calculating the average gradient direction for each layer\n",
        "w3_update = np.dot(output.T, layer3_grad) / N\n",
        "w2_update = np.dot(act_layer2.T, layer2_grad) / N\n",
        "w1_update = np.dot(act_layer1.T, layer1_grad) / N\n",
        "\n",
        "#Updating the new weights by magnitude of the learning rate\n",
        "w3_new = w3 - learning_rate * w3_update.T\n",
        "w2_new = w2 - learning_rate * w2_update.T\n",
        "w1_new = w1 - learning_rate * w1_update.T\n",
        "\n",
        "#Updating the new biases\n",
        "b3_new = b3 - learning_rate * output_error\n",
        "b2_new = b2 - learning_rate * layer3_error\n",
        "b1_new = b1 - learning_rate * layer2_error\n"
      ],
      "metadata": {
        "id": "UaiCeYv9wZ89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Second pass through forward direction and\n",
        "#error calculation\n",
        "\n",
        "layer1_new = np.dot(single_xtrain,w1_new)+b1_new\n",
        "act_layer1_new = sigmd(layer1_new)\n",
        "\n",
        "layer2_new = np.dot(act_layer1_new,w2_new)+b2_new\n",
        "act_layer2_new = sigmd(layer2_new)\n",
        "\n",
        "layer3_new = np.dot(act_layer2_new,w3_new)+b3_new\n",
        "output_new = sigmd(layer3_new)\n",
        "\n",
        "mse(single_ytrain, output_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXndUShrF5Bb",
        "outputId": "f96ff7a8-adbd-4201-b29b-5621fdaca877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3487951706994674"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}
